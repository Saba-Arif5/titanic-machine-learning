{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f80dc74a-b075-46c7-98fe-42ea91a0f6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923dbffc-b1a5-4d5f-8c25-e53e06710075",
   "metadata": {},
   "source": [
    "## Feature Importance with Logistic Regression\n",
    "\n",
    "### What I Did\n",
    "\n",
    "- Reused the processed Titanic dataset from Day 25.\n",
    "- Fit a Logistic Regression model on selected features.\n",
    "- Extracted feature coefficients as a measure of feature importance.\n",
    "- Sorted and displayed them to see strongest predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c7d80e0-56b0-4da9-af5b-06025a9b000e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('datasets/cleaned_titanic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a3b90c3-f22b-46c3-91b1-68161575fb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Sex'] = df['Sex'].map({'male': 1, 'female': 0})\n",
    "df = pd.get_dummies(df, columns=['Embarked'], drop_first=True)\n",
    "\n",
    "cleaned_df = df[['Age', 'Pclass', 'Fare','Embarked_Q','Sex', 'Embarked_S', 'SibSp','Survived']].dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41cf5159-047d-48d1-bf49-448cc754ac3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "features=cleaned_df[['Age', 'Pclass', 'Fare','Embarked_Q','Sex', 'Embarked_S', 'SibSp']]\n",
    "target=cleaned_df['Survived']\n",
    "X=features\n",
    "X.shape\n",
    "y=target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d564402e-48c5-488c-a214-1451968b7ce0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((571, 7), (143, 7))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train,X_test, y_train, y_test=train_test_split(X,y, test_size=0.2,random_state=42)\n",
    "\n",
    "X_train.shape,X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "acf27e1d-d9b1-4ec2-a12d-36d905bac72c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Coefficient</th>\n",
       "      <th>abscoeff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sex</td>\n",
       "      <td>-2.592794</td>\n",
       "      <td>2.592794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pclass</td>\n",
       "      <td>-1.190557</td>\n",
       "      <td>1.190557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Embarked_Q</td>\n",
       "      <td>-0.371773</td>\n",
       "      <td>0.371773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Embarked_S</td>\n",
       "      <td>-0.370920</td>\n",
       "      <td>0.370920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SibSp</td>\n",
       "      <td>-0.351259</td>\n",
       "      <td>0.351259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Age</td>\n",
       "      <td>-0.047655</td>\n",
       "      <td>0.047655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fare</td>\n",
       "      <td>0.001107</td>\n",
       "      <td>0.001107</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Feature  Coefficient  abscoeff\n",
       "4         Sex    -2.592794  2.592794\n",
       "1      Pclass    -1.190557  1.190557\n",
       "3  Embarked_Q    -0.371773  0.371773\n",
       "5  Embarked_S    -0.370920  0.370920\n",
       "6       SibSp    -0.351259  0.351259\n",
       "0         Age    -0.047655  0.047655\n",
       "2        Fare     0.001107  0.001107"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(max_iter=200)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Extract coefficients\n",
    "coef = model.coef_[0]\n",
    "coeff_df = pd.DataFrame({\n",
    "    'Feature': features.columns,\n",
    "    'Coefficient': coef,\n",
    "    'abscoeff': abs(coef)\n",
    "})\n",
    "\n",
    "coeff_df_sorted = coeff_df.sort_values(by='abscoeff', ascending=False)\n",
    "coeff_df_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2af9716-e05a-4e12-9d80-205074f52c3d",
   "metadata": {},
   "source": [
    "## What the Output Shows\n",
    "\n",
    "- Features at the top have the strongest positive contribution to survival predictions.\n",
    "- Features with negative coefficients reduce survival probability.\n",
    "\n",
    "Features closer to 0 have weaker impact.\n",
    "\n",
    "## Insights\n",
    "\n",
    "- Gender and class are the most influential predictors in the Titanic dataset.\n",
    "- Logistic Regression coefficients help determine how each feature affects survival.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04cc66f3-c1bb-42ae-a4ad-26c19a3178ca",
   "metadata": {},
   "source": [
    "## Evaluation:\n",
    "\n",
    "**Why can negative coefficients be just as important as positive coefficients in logistic regression?**\n",
    "Negative coefficients are as important as positive ones because they indicate features that decrease the probability (odds) of the positive class. For example, if Sex is encoded as male=1, a negative coefficient for that variable means being male is associated with lower odds of survival. Note: coefficient magnitudes are easier to compare when features are scaled to the same units.\n",
    "\n",
    "**What do they represent about the relationship between the feature and the prediction?**\n",
    "They represent an inverse relationship between the feature and the predicted probability of the positive class.\n",
    "Specifically, a negative coefficient means that as the feature value increases, the model predicts lower odds of the target outcome, holding other features constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a871f6e-c20a-4b9c-8278-279403dfb666",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
