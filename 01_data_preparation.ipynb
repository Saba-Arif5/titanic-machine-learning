{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57dfba3a-934c-4cdd-a3f2-389591e92d49",
   "metadata": {},
   "source": [
    "### Train/Test Split on Titanic Dataset\n",
    "\n",
    "**Summary:** This notebook prepares the Titanic dataset for machine-learning modeling by selecting relevant features and dividing the data into training and testing sets.\n",
    "The workflow includes loading the cleaned dataset, choosing input variables, defining the target, and applying an 80/20 split for model evaluation.\n",
    "\n",
    "**Goal:** The goal of this notebook is to correctly separate the dataset into training and testing subsets so that machine-learning models can be trained on one portion and evaluated on unseen data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad7c2e48-91df-49f1-a090-98e824ac1a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de0f0c25-df53-4946-ba8b-292fa35743a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('datasets/cleaned_titanic.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d8768f5-54af-4911-89d2-f8a99b81a728",
   "metadata": {},
   "outputs": [],
   "source": [
    "X= df[['Age', 'Pclass','Fare']]\n",
    "y= df['Survived']\n",
    "\n",
    "X_train, X_test,y_train, y_test= train_test_split(X,y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c6893b9-f34f-4b32-9b5a-943b6258033f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((712, 3), (179, 3))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e7722a-081d-461f-a272-cc514992e02a",
   "metadata": {},
   "source": [
    "\n",
    "### Train/Test Split Preparation\n",
    "\n",
    "### What I Did\n",
    "- Loaded the cleaned Titanic dataset using `read_csv`.  \n",
    "- Selected `Age`, `Pclass`, and `Fare` as feature variables (X).  \n",
    "- Chose `Survived` as the target variable (y).  \n",
    "- Applied `train_test_split()` to generate training (80%) and testing (20%) sets.\n",
    "\n",
    "### What the Output Shows\n",
    "- The shapes of `X_train` and `X_test` represent how many samples went into each subset.  \n",
    "- The `random_state=42` ensures the split is reproducible.  \n",
    "- The dataset is now divided and ready for model training.\n",
    "\n",
    "### Insights\n",
    "- An 80/20 split provides a strong balance between training data and evaluation data.  \n",
    "- This step is essential before building Logistic Regression or any supervised model.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a0c5af-f9f3-45c1-932f-810d81b9b5e1",
   "metadata": {},
   "source": [
    "## Evaluation Prompt\n",
    "\n",
    "**Suppose your dataset is very small (only 200 rows).\n",
    "Would an 80/20 split still be appropriate, or would another method like cross-validation be safer?\n",
    "Explain why**\n",
    "\n",
    "if a dataset is very samll having only 200 rows then it would be difficult to have accurate evalution as even 2 percent of uncertainity whould affect the entire model evaluation\n",
    "\n",
    "if a dataset has only 200 row then:\n",
    "  - Training set = 160 rows\n",
    "  - Testing set = 40 rows\n",
    "This means that if a set having only 40 rows is too small to reliably evaluate model performance.\n",
    "If you get 2 wrong predictions, your accuracy suddenly drops by 5 percent.\n",
    "This makes results unstable and unreliable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75422483-b7b5-4cc9-8d4c-ecdd379b717e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
